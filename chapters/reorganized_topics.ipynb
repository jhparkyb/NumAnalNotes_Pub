{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropped from na02approximation.ipynb\n",
    "\n",
    "Move to M104C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![Chebychev polynomial 3](https://jhparkyb.github.io/resources/notes/na/104ASlides_Approximation021.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Divided differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Divided differences 1](https://jhparkyb.github.io/resources/notes/na/104ASlides_Approximation026.png)\n",
    "\n",
    "![Divided differences 2](https://jhparkyb.github.io/resources/notes/na/104ASlides_Approximation027.png)\n",
    "\n",
    "![Divided differences 3](https://jhparkyb.github.io/resources/notes/na/104ASlides_Approximation028.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Horner's algorithm: efficient evaluation of interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efficient way of evaluating polynomails.\n",
    "\n",
    "![Example of Horner's algorithm](https://jhparkyb.github.io/resources/notes/na/104ASlides_Approximation010.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Finding interpolating polynomial in the Newton form 2](https://jhparkyb.github.io/resources/notes/na/104ABoardWork_Approximation002.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swaping\n",
    "<!-- **Motivating example**\n",
    "\n",
    "See the example below. There are no errors or bugs in the function `gauss_elimination2D`. But it produces something weird: `x_lib` is the correct solution, which is obtained by `numpy.linalg` (which uses LAPACK library). What has happened? -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swaping\n",
    "<!-- import numpy as np\n",
    "\n",
    "def gauss_elimination2D(AA, bb):\n",
    "    \"\"\"Solves Ax = b using Gauss elimination.\n",
    "\n",
    "    Args:\n",
    "        A: A square matrix.\n",
    "        b: A vector.\n",
    "\n",
    "    Returns:\n",
    "        x: A vector.\n",
    "    \"\"\"\n",
    "    n = 2\n",
    "    AA = A.copy()\n",
    "    bb = b.copy()\n",
    "    x = np.zeros(n).reshape(-1, 1)\n",
    "\n",
    "    m = AA[1, 0] / AA[0, 0]\n",
    "    AA[1, 1] -= m * AA[1, 0]\n",
    "    bb[1] -= m * bb[0]\n",
    "    \n",
    "    x[1] = bb[1] / AA[1, 1]\n",
    "    x[0] = (bb[0] - AA[0, 1] * x[1]) / AA[0, 0]\n",
    "    \n",
    "    return x\n",
    "\n",
    "A = np.array([[10e-20,  1.], \n",
    "              [     1.,  2.]])\n",
    "b = np.array([1., 4.]).reshape(-1, 1)\n",
    "\n",
    "x_naive = gauss_elimination2D(A, b)\n",
    "x_lib = np.linalg.solve(A, b)\n",
    "\n",
    "print(\"x_naive: \\n\", x_naive)\n",
    "print(\"x: \\n\", x) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- #### Inner product\n",
    "\n",
    "Inner product is a far-reaching concept that helps us tackle differential geometry, Fourier analysis, solutions of partial differential equations just to name a few. Here, we give just a bit more details to see if the $$(f,g)_w:=\\int_a^b f(x)g(x)w(x)dx$$ is indeed an inner product. -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
