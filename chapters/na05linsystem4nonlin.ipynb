{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Take-aways\n",
    "\n",
    "After studying this material, we will be able to\n",
    "\n",
    "- TBF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem of interest**\n",
    "\n",
    "Given $F:\\mathbb{R}^{n}\\to \\mathbb{R}^{n}$, find $x \\in \\mathbb{R}^{n}$ such that\n",
    "\n",
    "$$ F(x) = 0, $$\n",
    "\n",
    "where $0$ means $n$ dimensional zero vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods\n",
    "\n",
    "- Newton's method\n",
    "- Broyden's methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Remark**\n",
    "\n",
    "- There are many other methods. \n",
    "- Methods for systems of nonlinear equations are way harder to study.\n",
    "- We touch on the most basic ones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newton's method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motivation**\n",
    "\n",
    "We can generalize 1D version of Newton's method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Algorithm** (Newton's method 1D)\n",
    ">\n",
    "> Given a differentiable function $f:\\mathbb{R}\\to\\mathbb{R}$ and an initial guess $x_0\\in\\mathbb{R}$, compute, for $n\\ge 0$,\n",
    ">\n",
    "> $$ x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** \n",
    "\n",
    "What's the analog of dividing by derivative in higher dimension?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Derivation of Newton's method](https://jhparkyb.github.io/resources/notes/na/der_NewtonMethodTaylor_lp2000.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition** (Jacobian matrix)\n",
    "\n",
    "If $F:\\mathbb{R}^{n} \\to \\mathbb{R}^{n}$ is defined by $F(x)=(f_1 (x), f_2(x), \\cdots, f_m(x))$, where $x=(x_1, x_2, \\cdots, x_n)$, then its *Jacobian matrix* is given by\n",
    "\n",
    "$$\n",
    "\\left[\\begin{array}{ccc}\n",
    "\\frac{\\partial f_1}{\\partial x_1} & \\cdots & \\frac{\\partial f_1}{\\partial x_n} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial f_m}{\\partial x_1} & \\cdots & \\frac{\\partial f_m}{\\partial x_n}\n",
    "\\end{array}\\right].\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- \n",
    "For example, if $n=3$ and $F:\\mathbb{R}^{3} \\to \\mathbb{R}^{3}$ is defined by $F(x)=(f_1 (x), f_2(x), f_3(x))$, where $x=(u,v,w)$, or in component form, $F(u, v, w)=(f_1(u, v, w), f_2(u, v, w), f_3(u, v, w))$, then its Jacobian matrix is given by\n",
    "\n",
    "$$\n",
    "D F(x)=\\begin{bmatrix}\n",
    "\\frac{\\partial f_1}{\\partial u} & \\frac{\\partial f_1}{\\partial v} & \\frac{\\partial f_1}{\\partial w} \\\\\n",
    "\\frac{\\partial f_2}{\\partial u} & \\frac{\\partial f_2}{\\partial v} & \\frac{\\partial f_2}{\\partial w} \\\\\n",
    "\\frac{\\partial f_3}{\\partial u} & \\frac{\\partial f_3}{\\partial v} & \\frac{\\partial f_3}{\\partial w}\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& f_1(u, v, w)=0 \\\\\n",
    "& f_2(u, v, w)=0 \\\\\n",
    "& f_3(u, v, w)=0\n",
    "\\end{aligned}\n",
    "$$ -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**\n",
    "\n",
    "Suppose \n",
    "\n",
    "$$\n",
    "F(u, v)=\\left(e^{u+v}, \\sin u\\right).\n",
    "$$\n",
    "\n",
    "Then, the Jacobian matrix at $(0,0)$ is \n",
    "$$\n",
    "DF(0,0) =\n",
    "\\left[\\begin{array}{cc}\n",
    "e^0 & e^0 \\\\\n",
    "\\cos 0 & 0\n",
    "\\end{array}\\right]\n",
    "=\n",
    "\\left[\\begin{array}{cc}\n",
    "1 & 1 \\\\\n",
    "1 & 0\n",
    "\\end{array}\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark**\n",
    "\n",
    "- Jacobian matrix must be evaluated at a point before it is used just as we do with the 1D derivative $f'$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algorithm** (Newton's method - multi-dimensional version)\n",
    "\n",
    "**Input**\n",
    "\n",
    "- $F:\\mathbb{R}^{n} \\to \\mathbb{R}^{n}$ (vector field)\n",
    "- $DF:\\mathbb{R}^{n} \\to \\mathbb{R}^{n\\times n}$ (Jacobian matrix)\n",
    "- $x_0 \\in \\mathbb{R}^{n}$ (initial guess)\n",
    "\n",
    "**Main loop**\n",
    "\n",
    "- **For** $k=0,1,2,\\cdots$, do\n",
    "  - $x_{k+1}=x_k-\\left(D F\\left(x_k\\right)\\right)^{-1} F\\left(x_k\\right)$\n",
    "\n",
    "**Output**\n",
    "\n",
    "- $x_\\infty$ (approximate solution of $F(x)=0$, where $0$ is the zero vector of length $n$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark** \n",
    "\n",
    "- In the main loop, we use Gauss elimination instead of inverting the Jacobian matrix.(Inverting a matrix is really expensive.)\n",
    "- The actual algorithm, then reads, \n",
    "  - $D F\\left(x_k\\right) s=-F\\left(x_k\\right)$ (solve for $s$)\n",
    "  - $x_{k+1}=x_k+s$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "- The analysis of multidimensional Newton's method is beyond the scope of our class.\n",
    "- The convergence rate of multidimensional Newton's method remains to be of 2nd order. \n",
    "- The derivation of the method and its convergence rate relies on multidimensional Taylor theorem. \n",
    "- The following is an linear approximation version of multidimensional Taylor theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "F(x)=F\\left(x_0\\right)+D F\\left(x_0\\right) \\cdot\\left(x-x_0\\right)+O\\left(\\|x-x_0 \\|^2\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark** (Multidimensional Taylor Theorem)\n",
    "\n",
    "- Multidimensional version of Taylor theorem requires a bit of preparation called *multi-index*. Otherwise, the most motivated person would find it extremely taxing working in only four dimension. However, using *multi-index,* the theorem reads almost exactly the same as in 1D. (For a look, see [Wikipedia](https://en.wikipedia.org/wiki/Taylor%27s_theorem#Taylor's_theorem_for_multivariate_functions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broyden's methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motivation**\n",
    "\n",
    "What if Jacobian matrix is not available? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark**\n",
    "\n",
    "- In 1D, we have Secant Method. However, since secant line is not clear in multi-dimensional setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algorithm** (Broyden's method 1)\n",
    "\n",
    "The following algorithm is borrowed from Sauer (2017) Numerical Analysis 3rd ed. p. 140.\n",
    "\n",
    "**Input**\n",
    "\n",
    "- $F:\\mathbb{R}^{n} \\to \\mathbb{R}^{n}$ (vector field)\n",
    "- $A_0\\in\\mathbb{R}^{n\\times n}$ (initial approximate Jacobian matrix)\n",
    "- $x_0 \\in \\mathbb{R}^{n}$ (initial guess)\n",
    "\n",
    "**Main loop**\n",
    "\n",
    "- **For** $i=0,1,2,\\cdots$, do\n",
    "  - $x_{i+1}=x_i-A_i^{-1} F\\left(x_i\\right)$\n",
    "  - $\\delta_{i+1}=x_{i+1}-x_i$\n",
    "  - $\\Delta_{i+1}=F\\left(x_{i+1}\\right)-F\\left(x_i\\right)$\n",
    "  - $A_{i+1}=A_i+\\frac{\\left(\\Delta_{i+1}-A_i \\delta_{i+1}\\right) \\delta_{i+1}^T}{\\delta_{i+1}^T \\delta_{i+1}}$\n",
    "\n",
    "**Output**\n",
    "\n",
    "- $x_\\infty$ (approximate solution of $F(x)=0$, where $0$ is the zero vector of length $n$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algorithm** (Broyden's method 2)\n",
    "\n",
    "The following algorithm is borrowed from Sauer (2017) Numerical Analysis 3rd ed. p. 141.\n",
    "\n",
    "**Input**\n",
    "\n",
    "- $F:\\mathbb{R}^{n} \\to \\mathbb{R}^{n}$ (vector field)\n",
    "- $B_0\\in\\mathbb{R}^{n\\times n}$ (initial approximate inverse Jacobian matrix)\n",
    "- $x_0 \\in \\mathbb{R}^{n}$ (initial guess)\n",
    "\n",
    "**Main loop**\n",
    "\n",
    "- **For** $i=0,1,2,\\cdots$, do\n",
    "  - $x_{i+1}=x_i-B_i F\\left(x_i\\right)$\n",
    "  - $\\delta_{i+1}=x_{i+1}-x_i$\n",
    "  - $\\Delta_{i+1}=F\\left(x_{i+1}\\right)-F\\left(x_i\\right)$\n",
    "  - $B_{i+1}=B_i+\\frac{\\left(\\delta_{i+1}-B_i \\Delta_{i+1}\\right) \\delta_{i+1}^T B_i}{\\delta_{i+1}^T B_i \\Delta_{i+1}}$\n",
    "\n",
    "**Output**\n",
    "\n",
    "- $x_\\infty$ (approximate solution of $F(x)=0$, where $0$ is the zero vector of length $n$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark** \n",
    "\n",
    "- Broyden's method 2 directly approximate the inverse of the Jacobian while Broyden's method 1 approximate the Jacobian itself.\n",
    "  - The last line of the main loop updates the approximation of the Jacobian or inverse of the Jacobian.\n",
    "- Both methods converges superlinearly (to simple roots): faster than linear convergence but slower than quadratic convergence. \n",
    "- If Jacobian is available, setting $B_0=DF(x_0)^{-1}$ usually speeds up the method 2.\n",
    "- Broyden named the method 1 *good* method, and the method 2 *bad* method. However, later, many other researchers found that method 2 works better overall. \n",
    "- There are further improved methods based on Broyden's methods. But we don't discuss them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark** (Comparison between Broyden's method 1 and 2)\n",
    "\n",
    "| | Broyden's method 1 | Broyden's method 2 |\n",
    "|---|---|---|\n",
    "| Linear system  | must be solved to move forward | no need to solve a linear system |\n",
    "| Approximate Jacobian | Available | Not available (only approximation of inverse is available) |\n",
    "\n",
    "- It may seem that obtaining approximate Jacobian is not necessary as long as the algorithm gives us the solution. However, according to Sauer (2017) Numerical Analysis 3rd ed. (p. 141), some applications need approximate Jacobian as well as the solution. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def broyden(F, x0, B0=None, tol=1e-6, maxiter=100):\n",
    "    \"\"\"\n",
    "    Solve F(x) = 0 using Broyden's \"bad\" method.\n",
    "    \n",
    "    Shapes\n",
    "        Input: row vectors\n",
    "        Internal computation: convert to column vectors\n",
    "        Output: convert back to row vectors\n",
    "    \"\"\"\n",
    "    x = x0.reshape(-1, 1)\n",
    "    B = B0 if B0 else np.eye(len(x0))\n",
    "    for i in range(maxiter):\n",
    "        Fx = F(x).reshape(-1, 1)\n",
    "        x_new = x - B @ Fx\n",
    "        d = x_new - x\n",
    "        D = F(x_new).reshape(-1, 1) - Fx\n",
    "        B += ((d - B @ D) @ d.T @ B) / (d.T @ B @ D)\n",
    "        x = x_new\n",
    "        if np.linalg.norm(F(x)) < tol:\n",
    "            break\n",
    "    return x.reshape(-1,), i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 53\n",
      "x = [0.99999998 0.99999998]\n",
      "F(x) = [-3.47756147e-07  1.54001867e-07]\n",
      "||F(x)|| = 3.8033000524341814e-07\n",
      "||x - x_exact|| = 2.9093487026234643e-08\n"
     ]
    }
   ],
   "source": [
    "def F(x):\n",
    "    \"\"\"\n",
    "    A vector feild from 2D to 2D.\n",
    "\n",
    "    Shapes\n",
    "        Input: any 1D array of length 2 or 2D array with shape (2, 1)\n",
    "        Output: row vector of shape (2,)\n",
    "    \"\"\"\n",
    "    if x.ndim == 1:\n",
    "        x = x.reshape(-1, 1)\n",
    "    \n",
    "    u = x[0, 0]\n",
    "    v = x[1, 0]\n",
    "\n",
    "    f1 = 6*u**3 + u*v - 3*v**2 - 4\n",
    "    f2 = u**2 - 18*u*v**2 + 16*v**3 + 1\n",
    "\n",
    "    return np.array([f1, f2])\n",
    "\n",
    "x0 = np.array([1.5, 1.5])\n",
    "\n",
    "x_exact = np.array([1., 1.])\n",
    "\n",
    "x, N = broyden(F, x0)\n",
    "\n",
    "print(\"N =\", N)\n",
    "print(\"x =\", x)\n",
    "print(\"F(x) =\", F(x))\n",
    "print(\"||F(x)|| =\", np.linalg.norm(F(x)))\n",
    "print(\"||x - x_exact|| =\", np.linalg.norm(x - x_exact))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptrch",
   "language": "python",
   "name": "ptrch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
