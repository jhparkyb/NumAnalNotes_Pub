{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamentals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take-aways\n",
    "\n",
    "- Efficient ways to compute polynomials\n",
    "  - Horner's algorithm\n",
    "- Computational ways of thinking\n",
    "  - They are often different from mathematics.\n",
    "  - They are often non-obvious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Horner's algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Devising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 1** (Simplest way)\n",
    "\n",
    "To make the discussion concrete, fix a polynomial\n",
    "\n",
    "$$\n",
    "p(x) = 2 x^4+3 x^3-3 x^2+5 x-1\n",
    "$$\n",
    "\n",
    "Plug in $1/2$\n",
    "\n",
    "$$\n",
    "P\\left(\\frac{1}{2}\\right)=2 * \\frac{1}{2} * \\frac{1}{2} * \\frac{1}{2} * \\frac{1}{2}+3 * \\frac{1}{2} * \\frac{1}{2} * \\frac{1}{2}-3 * \\frac{1}{2} * \\frac{1}{2}+5 * \\frac{1}{2}-1=\\frac{5}{4}\n",
    "$$\n",
    "\n",
    "Complexity: count `*` and `+` (or `-`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 2** (Recycle previous powers)\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{1}{2} * \\frac{1}{2} & =\\left(\\frac{1}{2}\\right)^2 \\\\\n",
    "\\left(\\frac{1}{2}\\right)^2 * \\frac{1}{2} & =\\left(\\frac{1}{2}\\right)^3 \\\\\n",
    "\\left(\\frac{1}{2}\\right)^3 * \\frac{1}{2} & =\\left(\\frac{1}{2}\\right)^4\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Take the linear combination:\n",
    "\n",
    "$$\n",
    "P\\left(\\frac{1}{2}\\right)=2 *\\left(\\frac{1}{2}\\right)^4+3 *\\left(\\frac{1}{2}\\right)^3-3 *\\left(\\frac{1}{2}\\right)^2+5 * \\frac{1}{2}-1=\\frac{5}{4} .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 3** (Horner's algorithm - Nested multiplication)\n",
    "\n",
    "Given\n",
    "\n",
    "$$\n",
    "p(x) = 2 x^4+3 x^3-3 x^2+5 x-1\n",
    "$$\n",
    "\n",
    "rewrite \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(x) & =-1+x\\left(5-3 x+3 x^2+2 x^3\\right) \\\\\n",
    "& =-1+x\\left(5+x\\left(-3+3 x+2 x^2\\right)\\right) \\\\\n",
    "& =-1+x(5+x(-3+x(3+2 x))) \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Then,\n",
    "\n",
    "$$\n",
    "P(\\frac{1}{2}) =-1+\\frac{1}{2} *(5+\\frac{1}{2} *(-3+\\frac{1}{2} *(3+\\frac{1}{2} * 2)))\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  | multiplication | addition |\n",
    "|---|---|---|\n",
    "| Method 1 | 10 | 4 |\n",
    "| Method 2 | 7 | 4 |\n",
    "| Method 3 | 4 | 4 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark** (Efficiency of Horner)\n",
    "\n",
    "- Horner's algorithm does not transform the coefficients, but use those numbers as they are $\\longrightarrow$ less computations are purely a gain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary\n",
    "\n",
    "Horner's algorithm for $p(x) = a_0+a_1 x+\\cdots+a_d x^d$ (degree $d$)\n",
    "\n",
    "- costs $d$ multiplications and $d$ additions\n",
    "- is based on rewriting: $a_0+x*\\left(a_1+x*\\left(a_2+\\cdots *\\left(a_{d-1}+x*\\left(a_d\\right)\\right)\\cdots\\right)\\right)$\n",
    "- A more general version uses base points $r_1, \\cdots, r_d$.\n",
    "  - $a_0+(x - r_1)*\\left(a_1 + (x - r_2)*\\left(a_2+\\cdots *\\left(a_{d-1}+(x - r_{d})*\\left(a_d\\right)\\right)\\cdots\\right)\\right)$\n",
    "  - This general version is useful in polynomial interpolation.\n",
    "  - $r_i=0$ ($i=1,2,\\cdots,d$) gives us the (plain) Horner form given above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example** (Horner's algorithm)\n",
    "\n",
    "Write a code that evaluates polynomials at different points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def poly_eval(a, x, algorithm='Horner'):\n",
    "    \"\"\"\n",
    "    Evaluates a polynomial at a given point x.\n",
    "\n",
    "    Inputs:\n",
    "        a: 1D array of polynomial coefficients (ascending order). \n",
    "        x: 1D array of points at which to evaluate the polynomial.\n",
    "        algorithm: algorithm to use for polynomial evaluation. (default: 'Horner')\n",
    "    Output:\n",
    "        p: array of polynomial values at x.\n",
    "    \"\"\"\n",
    "    \n",
    "    if algorithm == 'Horner':\n",
    "        p = a[-1]*np.ones_like(x) # broadcasting is in effect \n",
    "        for i in range(len(a)-2, -1, -1):\n",
    "            p = x*p + a[i]\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.97789397   3.20347077  12.09489626  33.21138221  72.11214039\n",
      " 134.35638257 225.50332052 351.11216602 516.74213083 727.95242674]\n"
     ]
    }
   ],
   "source": [
    "d = 4\n",
    "# a = np.ones(d, dtype=np.float64)\n",
    "a = np.random.rand(d)\n",
    "x = np.arange(10)\n",
    "p = poly_eval(a, x)\n",
    "\n",
    "print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot part is generated by Copilot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scatter plot of p at x\n",
    "plt.scatter(x, p, label='Horner algorithm')\n",
    "\n",
    "# Polynomial plot\n",
    "poly = np.poly1d(a[::-1])  # Create a polynomial object with coefficients in ascending order\n",
    "plt.plot(x, poly(x), label='numpy package')\n",
    "\n",
    "# Set labels and legend\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark**\n",
    "\n",
    "- You might think the difference is not a big deal. What would you pursue if your numerical problem may end up evaluating polynomials millions or billions of times?\n",
    "  - This is indeed true when you solve nonlinear PDE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Floating point representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take-aways\n",
    "\n",
    "- How computers carry out computations\n",
    "  - IEEE 754 Floating Point System\n",
    "  - Loss of significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IEEE 754 Floating Point Standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Scientific representation of a real number](https://fastbitlab.com/wp-content/uploads/2022/07/Figure-2-7-1536x793.png)\n",
    "\n",
    "Figure: FastBitLab (Scientific representation of a real number)\n",
    "\n",
    "![IEEE 754 Single Precision](https://i0.wp.com/circuitcellar.com/wp-content/uploads/2023/07/0067-Floating-Point_Representation_Feature_Image.png?w=1123&ssl=1)\n",
    "\n",
    "Figure: Andrew Levido\n",
    "\n",
    "The two figures describe different numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "- Real numbers are stored by a binary number system\n",
    "  - $\\pm 1 . b_1 b_2 \\ldots b_n \\times 2^e$\n",
    "  - IEEE Rounding to Nearest Rule applies when store real numbers. (See below)\n",
    "- Most common formats\n",
    "\n",
    "| precision | sign ($s$) | exponent ($e$)| mantissa or <br> fraction ($b$) | total bits |\n",
    "| :--- | :---: | :---: | :---: | :---: |\n",
    "| single | 1 | 8 | 23 | 32 |\n",
    "| double | 1 | 11 | 52 | 64 |\n",
    "| long double | 1 | 15 | 64 | 80 |\n",
    "\n",
    "Table source: Sauer (2017) p. 9.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark** \n",
    "\n",
    "- From now on, we mostly focus on double precision otherwise mentioned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Terminology** \n",
    "\n",
    "- Radix point: $1010\\underbrace{.}_{\\text{this}}011_{(2)}$\n",
    "- Normalized IEEE floating point number: The leading bit is 1.\n",
    "  - Subnormal: The leading bit is 0.\n",
    "- Left-justified: There is only one nonzero digit to the left of the radix point.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition** (Machine epsilon)\n",
    "\n",
    "The number *machine epsilon*, denoted $\\epsilon_{\\mathrm{mach}}$, is the distance between 1 and the smallest floating point number greater than 1. For the IEEE double precision floating point\n",
    "standard, $\\epsilon_{\\mathrm{mach}} = 2^{−52}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IEEE Rounding to Nearest Rule**\n",
    "\n",
    "For double precision, if the 53rd bit to the right of the binary point is 0, then round\n",
    "down (truncate after the 52nd bit). If the 53rd bit is 1, then round up (add 1 to the 52\n",
    "bit), unless all known bits to the right of the 1 are 0’s, in which case 1 is added to bit\n",
    "52 if and only if bit 52 is 1.\n",
    "\n",
    "Reference: Sauer (2017) p. 10.\n",
    "\n",
    "**Remark** \n",
    "\n",
    "- The last part starting with \"unless all known ...\" is to ensure that the rounding up and down have equal probabilities, hence no bias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notation**\n",
    "\n",
    "Denote the IEEE double precision floating point number associated to $x$, using the\n",
    "Rounding to Nearest Rule, by $\\mathrm{fl}(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathrm{fl}(x)$ is obtained as follows.\n",
    "\n",
    "1. Convert $x$ to binary number.\n",
    "2. Justify: Shift radix point to the right of the leftmost 1, and compensate with the exponent.\n",
    "2. Round: Apply a rounding rule, such as the IEEE Rounding to Nearest Rule, to reduce\n",
    "the mantissa to 52 bits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition** (Rounding errors)\n",
    "\n",
    "Let $x_c$ be a computed version of the exact quantity $x$. Then,\n",
    "$$\n",
    "\\text { (absolute) rounding error }=\\left|x_c-x\\right|,\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\text { relative rounding error }=\\frac{\\left|x_c-x\\right|}{|x|},\n",
    "$$\n",
    "if the latter quantity exists. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem** (Relative rounding error)\n",
    "\n",
    "In the IEEE machine arithmetic model, the relative rounding error of $\\mathrm{fl}(x)$ is no more than one-half machine epsilon:\n",
    "\n",
    "$$\n",
    "\\frac{|\\mathrm{fl}(x)-x|}{|x|} \\leq \\frac{1}{2} \\epsilon_{\\text {mach }}\n",
    "$$\n",
    "\n",
    "Reference: Sauer (2017) p. 11\n",
    "\n",
    "See [Remark (Computations with small numbers)](#computations-with-small-numbers) for an example of this bound."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Double precision**\n",
    "\n",
    "- $(-1)^{\\text {sign }}\\left(1 . b_{51} b_{50} \\ldots b_0\\right)_2 \\times 2^{e-1023}$\n",
    "\n",
    "![Double precision bits](https://upload.wikimedia.org/wikipedia/commons/thumb/a/a9/IEEE_754_Double_Floating_Point_Format.svg/618px-IEEE_754_Double_Floating_Point_Format.svg.png)\n",
    "\n",
    "- Exponent ranges $-1022 \\le e \\le 1023$.\n",
    "  - 1023 is called *exponent bias*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hexadecimal representation**\n",
    "\n",
    "- Binary nunmbers are often represented by hexadecimal numbers.\n",
    "- 4 bits $\\longleftrightarrow$ 1 hexadecimal digit\n",
    "\n",
    "|      Decimal | 0 | 1 |  2 |  3 |   4 |   5 |   6 |   7 |    8 |    9 |   10 |   11 |   12 |   13 |   14 |   15 |\n",
    "|-------------:|--:|--:|---:|---:|----:|----:|----:|----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|-----:|\n",
    "| 4-bit Binary | 0 | 1 | 10 | 11 | 100 | 101 | 110 | 111 | 1000 | 1001 | 1010 | 1011 | 1100 | 1101 | 1110 | 1111 |\n",
    "|  Hexadecimal | 0 | 1 |  2 |  3 |   4 |   5 |   6 |   7 |    8 |    9 |    A |    B |    C |    D |    E |    F |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example** \n",
    "\n",
    "Find computer-friendly representation of 9.4. More specifically, find its IEEE double precision floating point representation in binary and hexadecimal format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Step 1: Convert to binary\n",
    "\n",
    "(For an algorithmic way, see Sauer (2017) p. 6.)\n",
    "\n",
    "- Integer part\n",
    "\n",
    "$$\n",
    "9 = 8 + 1 = 1000_{(2)} + 1_{(2)} = 1001_{(2)}\n",
    "$$\n",
    "\n",
    "- Fraction part \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "0.4 =\\frac{2}{5}&= \\underbrace{0\\cdot\\frac{1}{2} + 1\\cdot\\frac{1}{2^2} + 1\\cdot\\frac{1}{2^3} + 0\\cdot\\frac{1}{2^4}}_{3/8 = 0.0110_{(2)}} + (\\underbrace{\\frac{4}{10} - \\frac{3}{8}}_{1/40})\\\\\n",
    "&= \\underbrace{0.0110_{(2)} + \\frac{1}{16} \\cdot \\frac{2}{5}}_{2/5\\text{ (plug this in)}}\n",
    "\\\\\n",
    "&= 0.0110_{(2)} + 0.0001_{(2)}\\cdot\\left(\\underbrace{0.0110_{(2)} + \\frac{1}{16} \\cdot \\frac{2}{5}}_{2/5\\text{ (plugged in)}}\\right) \n",
    "\\\\\n",
    "&= 0.0110_{(2)} + 0.00000110_{(2)} + (0.0001_{(2)})^2\\cdot\\left( 0.0110_{(2)} + \\frac{1}{16} \\cdot \\frac{2}{5}\\right) %0.0110_{(2)} + \\underbrace{\\frac{1}{40}}_{(1/16)\\cdot (2/5)})\n",
    "\\\\\n",
    "&\\quad\\vdots\n",
    "\\\\\n",
    "&=0.\\overline{0110}_{(2)}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Therefore, \n",
    "\n",
    "$$\n",
    "9.4 = 1001.\\overline{0110}_{(2)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Justify\n",
    "\n",
    "$$\n",
    "1001.\\overline{0110}_{(2)} = 1.001\\overline{0110}_{(2)}\\times 2^3 %= 1.001\\overline{0110}_{(2)}\\times 2^{11_{(2)}}\n",
    "$$\n",
    "\n",
    "- Sign: $+$  $\\longrightarrow$ $s=0$\n",
    "- Exponent\n",
    "  - $3=1026-1023=(1024+2) - \\underbrace{1023}_{\\text{bias}}$ $\\longrightarrow$ $e=2^{10} + 2=100,0000,0010_{(2)}$\n",
    "- Sign + Exponent\n",
    "  - $0100,0000,0010_{(2)}=402_{(16)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Round to obtain mantissa\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "&\\quad 1.001\\overline{0110}_{(2)} \n",
    "\\\\\n",
    "&= 1.\n",
    "\\begin{array}{|l|l|l|l|l|l|l|l|l|l|l|l|l|}\n",
    "\\hline 0010 & 1100 & 1100 & 1100 & 1100 & 1100 & 1100 & 1100 & 1100 & 1100 & 1100 & 1100 & 1100 \\\\\n",
    "\\hline\n",
    "\\end{array} 110\\cdots\n",
    "\\\\\n",
    "&\\approx 1.\n",
    "\\begin{array}{|l|l|l|l|l|l|l|l|l|l|l|l|l|}\n",
    "\\hline 0010 & 1100 & 1100 & 1100 & 1100 & 1100 & 1100 & 1100 & 1100 & 1100 & 1100 & 1100 & 1101 \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Convert the mantissa to hexadecimal (excluding the leading 1)\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\begin{array}{|l|l|l|l|l|l|l|l|l|l|l|l|l|}\n",
    "\\hline 0010 & 1100 & 1100 & 1100 & 1100 & 1100 & 1100 & 1100 & 1100 & 1100 & 1100 & 1100 & 1101 \\\\\n",
    "\\hline\n",
    "\\end{array}\\\\\n",
    "&\\rightarrow(2 C C C C C C C C C C C D)_{16} .\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Altogether (sign bit) + (exponent bits) + (mantissa bits) reads\n",
    "\n",
    "- (Hexadecimal) $4022 C C C C C C C C C C C D$ \n",
    "- (Binary) $\\begin{array}{|l|l|l|l|l|l|l|l|l|l|l|l|l|l|l|l|}\n",
    "\\hline 0100 & 0000 & 0010 & 0010 & 1100 & 1100 & 1100 & 1100 & 1100 & 1100 & 1100 & 1100 & 1100 & 1100 & 1100 & 1101 \\\\\n",
    "\\hline\n",
    "\\end{array}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example** \n",
    "\n",
    "Use NumPy to check the IEEE 754 doulbe precision representation of 9.4.\n",
    "\n",
    "- `ndarray.view(dtype)`: Shows reinterpretation of the array in the format of `dtype`. ([Documentation](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.view.html))\n",
    "  - E.g., if `x = np.array(9.4)`, then `x.view(np.int64)` reinterpret the chunk of bit for 9.4, a 64-digit binary number, as an integer. In words, it says to NumPy \"View `x` as integer.\"\n",
    "- `numpy.binary_repr`: Return the binary representation of the input number as a string. ([Documentation](https://numpy.org/doc/stable/reference/generated/numpy.binary_repr.html))\n",
    "  - If `width=64` is passed, the output consists of all 64 bits, including the first consecutive 0's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Usual print of 9.4            :9.4\n",
      "   Float interpretation of 9.4            :9.4\n",
      " Integer interpretation of 9.4  (base  2) :0100000000100010110011001100110011001100110011001100110011001101\n",
      " Integer interpretation of 9.4  (base 10) :4621481347616918733\n",
      " Integer interpretation of 9.4  (base 16) :4022CCCCCCCCCCCD\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array(9.4)\n",
    "print(f\"{'Usual print of '              :>27}{x}{':'            :>13}{x.view(np.float64)}\")\n",
    "print(f\"{'Float interpretation of '     :>27}{x}{':'            :>13}{x.view(np.float64)}\")\n",
    "print(f\"{'Integer interpretation of '   :>27}{x}{' (base  2) :' :>13}{np.binary_repr(x.view(np.int64), width=64)}\")\n",
    "print(f\"{'Integer interpretation of '   :>27}{x}{' (base 10) :' :>13}{x.view(np.int64)}\")\n",
    "print(f\"{'Integer interpretation of '   :>27}{x}{' (base 16) :' :>13}{np.base_repr(x.view(np.int64), base=16)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Special exponent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $e=2047=111,1111,1111_{(2)}$ is used to express abnormal quantities.\n",
    "  - $s=0$ $\\longrightarrow$ $se=0111,1111,1111_{(2)}=7FF_{(16)}$\n",
    "  - $s=1$ $\\longrightarrow$ $se=1111,1111,1111_{(2)}=FFF_{(16)}$\n",
    "\n",
    "| machine number | example | hex format |\n",
    "| :---: | ---: | :---: |\n",
    "| + Inf | $1 / 0$ | 7FF0000000000000 |\n",
    "| - Inf | $-1 / 0$ | FFF0000000000000 |\n",
    "| NaN | $0 / 0$ | FFFxxxxxxxxxxxxx |\n",
    "\n",
    "Here, x means any digit not all of which are zero.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- $e=0=000,0000,0000_{(2)}$ is used to represent very small numbers.\n",
    "  - In this case **only**, the omitted bit to the right of radix point is assumed to be 0, not 1. \n",
    "    - Consequently, the floating point representation means $\\pm 0 . b_1 b_2 \\ldots b_{52} \\times 2^{-1022}$. (Sauer (2017) p. 13)\n",
    "    - Those numbers are called *subnormal* floating point numbers.\n",
    "  - Subnormal numbers include $0$.\n",
    "    - In fact, many computing system uses two zeros: `0` and `-0` depending on the sign bit.\n",
    "  - The exponent is the same, -1022, in the case $e=1=000,000,0001_{(2)}$ after subtracting the exponent bias $1023$. However, the actual effect is as if $(\\text{base})\\times 2^{-1023}$ because the leading digit is 0, not 1. (Instructor's comment)\n",
    "  - The smallest possible positive number of double precision is $2^{-52}\\times 2^{-1022}=2^{-1074}$, which is represented with 0 exponent\n",
    "  \n",
    "$$\n",
    "\\begin{array}{|l|l|l|l|}\n",
    "\\hline 0 & 00000000000 & 0000000000000000000000000000000000000000000000000001 \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5e-324\n",
      "Ex1   (bit): 1000000000000000000000000000000000000000000000000000000000000001\n",
      "    (float): -5e-324\n",
      "Ex2   (bit): 0000000000001000000000000000000000000000000000000000000000000000\n",
      "    (float): 1.1125369292536007e-308\n",
      "Ex3   (bit): 0000000000010000000000000000000000000000000000000000000000000000\n",
      "    (float): 2.2250738585072014e-308\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "i = 1\n",
    "x = np.array(1, dtype=np.int64)\n",
    "print(x.view(np.float64))\n",
    "\n",
    "# flip the sign bit\n",
    "# 1 is at the first (sign) and the last bits (mantissa)\n",
    "y = x + np.left_shift(x, 63)\n",
    "print(f\"{'Ex1   (bit): '    :>13}{np.binary_repr(y, width=64)}\")\n",
    "print(f\"{'(float): '  :>13}{y.view(np.float64)}\")\n",
    "\n",
    "# 0.1*2^(-1022) = 1.0*2^(-1023)\n",
    "# 1 is at the leftmost bit of the mantissa (0 exponent; subnormal)\n",
    "y = np.left_shift(x, 51)\n",
    "print(f\"{'Ex2   (bit): '    :>13}{np.binary_repr(y, width=64)}\")\n",
    "print(f\"{'(float): '  :>13}{y.view(np.float64)}\")\n",
    "\n",
    "# 1.0*2^(-1022)\n",
    "# 1 is at the rightmost bit of the exponent (1 exponent; normalized)\n",
    "y = np.left_shift(x, 52)\n",
    "print(f\"{'Ex3   (bit): '    :>13}{np.binary_repr(y, width=64)}\")\n",
    "print(f\"{'(float): '  :>13}{y.view(np.float64)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark** (Machine epsilon and smallest numbers)\n",
    "\n",
    "- $\\epsilon_{\\text {mach }}=2^{-52}$ is the smallest distinguishable size between numbers in the order of unit, 1.\n",
    "- The smallest-representable number, $2^{-1074}$ is the smallest quantity that can ever be representable: smaller values than that are treated as 0.\n",
    "- $\\epsilon_{\\text {mach }}=2^{-52}$ and $2^{-1074}$ are different.\n",
    "  - $\\epsilon_{\\text {mach }}$ originates from the mantissa while $2^{-1074}$ is determined by the mantissa and the exponent.\n",
    "  - There are many numbers that are smaller than $\\epsilon_{\\text {mach }}$ and represented by IEEE 754 double precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark** (Overflow and underflow)\n",
    "\n",
    "- Overflow refers to when the result is too large to be stored. \n",
    "  - They are usually stored as `Inf`, `-Inf`, or `NaN`.\n",
    "- Underflow refers to when the result is too small te be represented.\n",
    "  - They are usually stored as 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Addtion of floating point numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algorithm** (Machine addition)\n",
    "\n",
    "- Given two numbers\n",
    "- Line up the decimal points\n",
    "- Add the two numbers\n",
    "- Store the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark** (Machine addition)\n",
    "\n",
    "- Actual addition can be conducted in higher precision than 52 bits: it takes place in a dedicated register. (Sauer (2017) p. 14)\n",
    "- But the result is rounded to 52 bits of mantissa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**\n",
    "\n",
    "$1 + 2^{-53}=1$ in double precision.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& =1.\\begin{array}{|l|lr|}\n",
    "\\hline 0000000000000000000000000000000000000000000000000000 & \\  &\\times 2^0 \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "\\\\\n",
    "& + 0.\\begin{array}{|l|ll|}\n",
    "\\hline\n",
    "0000000000000000000000000000000000000000000000000000 & 1 & \\times 2^0 \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "\\\\\n",
    "& =1.\\begin{array}{|l|ll|}\n",
    "\\hline\n",
    "0000000000000000000000000000000000000000000000000000 & 1 & \\times 2^0 \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  x: 1.0\n",
      "  y: 1.1102230246251565e-16\n",
      "  z: 2.220446049250313e-16\n",
      "x+y: 1.0\n",
      "x+z: 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "x = 1.0\n",
    "y = 2**(-53)\n",
    "z = 2**(-52)\n",
    "\n",
    "print(f\"{'x: ' :>5}{x}\")\n",
    "print(f\"{'y: ' :>5}{y}\")\n",
    "print(f\"{'z: ' :>5}{z}\")\n",
    "print(f\"{'x+y: ' :>5}{x+y}\")\n",
    "print(f\"{'x+z: ' :>5}{x+z}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark** (Computation errors)\n",
    "\n",
    "- Due to rounding and truncations, computer arithemetic sometimes gives surprising results. For example, if a double precision computer with IEEE rounding to nearest is asked to store 9.4, then subtract 9, and then subtract 0.4, the result will be something other than zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  x: 9.4\n",
      "  y: 0.0\n",
      "  z: 3.3306690738754696e-16\n"
     ]
    }
   ],
   "source": [
    "x = 9.4\n",
    "y = x - 9.4\n",
    "z = x - 9.0\n",
    "z = z - 0.4\n",
    "\n",
    "print(f\"{'x: ' :>5}{x}\")\n",
    "print(f\"{'y: ' :>5}{y}\")\n",
    "print(f\"{'z: ' :>5}{z}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Computations with small numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark** (Computations with small numbers)\n",
    "\n",
    "- The fact that $\\epsilon_{\\text {mach }}=2^{-52}$ does not mean that numbers smaller than $\\epsilon_{\\text {mach }}$  are negligible in the IEEE model. As long as they are representable in the model, computations with numbers of this size are just as accurate, assuming that they are not added or subtracted to numbers of unit size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  x: 9.4e-20\n",
      "  y: 0.0\n",
      "  z: 1.2789378536946488e-35\n"
     ]
    }
   ],
   "source": [
    "r = 1e-20\n",
    "x = 9.4 * r\n",
    "y = x - (9.4 * r)\n",
    "z = x - (9.0 * r)\n",
    "z = z - (0.4 * r)\n",
    "\n",
    "print(f\"{'x: ' :>5}{x}\")\n",
    "print(f\"{'y: ' :>5}{y}\")\n",
    "# The computing error is not of order of machine epsilon,\n",
    "# but it is compatible with (x * e_mach)\n",
    "print(f\"{'z: ' :>5}{z}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss of significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptrch",
   "language": "python",
   "name": "ptrch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
