{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Finding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview\n",
    "\n",
    "##### Problem of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***Problem of interest***\n",
    ">\n",
    "> Given a function $f:\\R \\to \\R$, find $\\xi\\in\\R$ such that\n",
    "> $$f(\\xi)=0.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Methods\n",
    "\n",
    "1. Bisection method\n",
    "1. Newton's method\n",
    "1. Secant method\n",
    "1. Fixed point iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bisection method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Method\n",
    "\n",
    "![Bisection illustration](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Bisection_method.svg/1024px-Bisection_method.svg.png)\n",
    "\n",
    "Figure: Wikipedia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Algorithm (Modified [Brenton LeMesurier's notes](https://lemesurierb.people.cofc.edu/elementary-numerical-analysis-python/notebooks/root-finding-by-interval-halving-python.html#error-tolerances-and-stopping-conditions))\n",
    "> \n",
    "> - Get an initial interval $[a, b]$ with a sign-change: $f(a) f(b) < 0$.\n",
    "> \n",
    "> - Choose $N$, maximum number of iterations.\n",
    "> \n",
    "> - for i from 1 to N:\n",
    "> <br>$\\quad$ $\\displaystyle c \\leftarrow \\frac{a + b}{2}$\n",
    "> <br>$\\quad$ if $f(a) f(c) < 0$ then:\n",
    "> <br>$\\quad$ $\\quad$ $b \\leftarrow c$\n",
    "> <br>$\\quad$ else:\n",
    "> <br>$\\quad$ $\\quad$ $a \\leftarrow c$\n",
    "> <br>$\\quad$ end if\n",
    "> <br>end for\n",
    "> \n",
    "> - The approximate root is the final value of $c$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary\n",
    "\n",
    "- If convergent, the bisection method converges to the solution linearly.\n",
    "> **Definition** (Linear convergence) \n",
    "> \n",
    "> Let $\\{x_n\\}_{n\\in\\mathbb{N}_0}$ be a sequence that converges to $\\xi$. We say that it converges *linearly* if there exists $\\lambda\\in(0,1)$ such that\n",
    "> $$ e_{n+1} = \\lambda e_n, $$\n",
    "> where $e_n:=|x_n - \\xi|$ for $n=0, 1, 2,\\cdots$. In words, it means *errors get shrunken by a factor of a fraction*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis\n",
    "\n",
    "![Convergence of bisection](https://jhparkyb.github.io/resources/notes/na/104ASlides_RootFinding011.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Newton's method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Method\n",
    "\n",
    "**Terminology**\n",
    "\n",
    "It is also called *Newton-Raphson* method.\n",
    "\n",
    "![Newton's method illustration](https://math24.net/images/newtons-method1.svg)\n",
    "\n",
    "Figure: https://math24.net/newtons-method.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Algorithm\n",
    ">\n",
    "> Given a differentiable function $f:\\mathbb{R}\\to\\mathbb{R}$ and an initial guess $x_0\\in\\mathbb{R}$, for $n\\ge 0$\n",
    ">\n",
    "> $$ x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Derivation of Newton's method using tangent line intuition**\n",
    "\n",
    "See Board work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***Remark***\n",
    ">\n",
    "> There are different styles of algorithm or pseudo-algorithm.\n",
    ">\n",
    "> | Mathematics- or idea-oriented pseudo-algorithm | Coding-oriented pseudo-algorithm |\n",
    "> |:---|:---|\n",
    "> |Given an initial guess $x_0$, <br> compute <br> $ x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}$ for $n\\ge 0$. | Input (or Data): $x_0$, $f$, $f'$ <br> Set: $Tol>0$, $x \\gets x_0$ <br> While $\\|x - x_{pre}\\| > Tol$: <br> $ \\quad \\quad x_{pre} \\gets x $ <br> $\\quad \\quad x \\gets x - \\frac{f(x)}{f'(x)}$ |\n",
    "> | Focus on the essence | Also consider some details in implementation. In particular, this usually includes *stopping criteria*. |  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Question\n",
    ">\n",
    "> Did you see any difference in *style* between the bisection and Newton's algorithms? Think, pair, share. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary\n",
    "\n",
    "- If a zero exists and the initial guess is *close* to the true solution, Newton's method converges quadratically fast.\n",
    "> **Definition** (Quadradic convergence) \n",
    "> \n",
    "> Let $\\{x_n\\}_{n\\in\\mathbb{N}}$ be a sequence that converges to $\\xi$. We say that it converges quadratically fast if there exists $C>0$ such that\n",
    "> $$ e_{n+1} = Ce_n^2, $$\n",
    "> where $e_n:=|x_n - \\xi|$ for $n=0, 1, 2,\\cdots$. In words, it means *errors get shrunken by a square of the previous error*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis\n",
    "\n",
    "**Derivation of Newton's method using Taylor theorem**\n",
    "\n",
    "![Derivation of Newton's method](https://jhparkyb.github.io/resources/notes/na/104ASlides_RootFinding014.png)\n",
    "\n",
    "See also board work.\n",
    "\n",
    "In favor of more computational activities, we skip the proof the quadratic convergence of Newton's method. But since Newton's method is highly relevant even these days and since it inspires many other methods, we include some history about it.\n",
    "\n",
    "> **Historical note**\n",
    ">\n",
    "> 1. Babylonians (1894 BC - 539 BC) used the method to approximate square roots. (Ref: [2, 3])\n",
    "> 1. In 1669, the method was employed by Newton for the cubic equation $3x^3 -2x-5 = 0$. (Ref: [1])\n",
    "> 1. In 1690, Raphson described the method for a general cubic equation $x^3 â€” bx = c$. (Ref: [1])\n",
    "> 1. In 1818, Fourier proved the quadratic convergence of the method. (Ref: [1])\n",
    "> 1. In 1829, Cauchy proved a convergence theorem which does not assume the existence of a solution. (existence of a solution is a consequence; but it assumes some other conditions on the iterates) (Ref: [1])\n",
    "> 1. In 1939, Kantorovich proved a convergence theorem in a very general setting. (Ref: [1])\n",
    "> 1. In 1948, Kantorovich proved an improved version, which is now called Kantorovich's theorem or the Newton-Kantorovich theorem: existence of a solution is not assumed and the convergence is quadratic in a very general setting. (Ref: [1])\n",
    "> \n",
    "> Reference\n",
    "> \n",
    "> [1] Brezinski (2001) Numerical Analysis: Historical Developments in the 20th Century. p. 242\n",
    "> \n",
    "> [2] Sauer (2017) Numerical Analysis p. 41\n",
    "> \n",
    "> [3] Wikipedia (Babylonia) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Secant method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Method\n",
    "\n",
    "**Idea**: Replace $f'(x_n)$ with something similar in Newton's method.\n",
    "\n",
    "![Secant method](https://mathworld.wolfram.com/images/eps-svg/SecantMethod_800.svg)\n",
    "\n",
    "Figure: Wolfram MathWorld.\n",
    "\n",
    "> ***Algorithm***\n",
    ">\n",
    "> $$ x_{n+1}=x_{n}-f\\left(x_{n}\\right)\\frac{\\left(x_{n}-x_{n-1}\\right)}{f\\left(x_{n}\\right)-f\\left(x_{n-1}\\right)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary\n",
    "\n",
    "- If the secant method converges, its rate of convergence is the *golden ratio* ($\\approx 1.618$).\n",
    "- User must feed **two initial guesses**.\n",
    "- It requires **only the function evaluation**, but not the derivatives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis\n",
    "\n",
    "In favor of more computational activities, we skip the proof the *superlinear* convergence (i.e., a convergence rate that is faster the linear: $e_{k+1} \\approx C e_k^\\alpha$ with $\\alpha>1$) of the secant method.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixed point iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Method\n",
    "\n",
    "**Terminology**\n",
    "\n",
    "It is also called *Picard iteration* or *functional iteration*.\n",
    "\n",
    "**Geometric interpretation**\n",
    "\n",
    "\"A picture paints a thousand words.\" \n",
    "\n",
    "![Fixed point iteration](https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Cosine_fixed_point.svg/1920px-Cosine_fixed_point.svg.png)\n",
    "\n",
    "Figure: Wikipedia\n",
    "\n",
    "[Fixed point iteration](https://www.geogebra.org/m/qUbg7Z6W) (Geogebra construction due to stuart.cork)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Algorithm\n",
    ">\n",
    "> Given a function $f:\\mathbb{R}\\to\\mathbb{R}$ and an initial guess $x_0\\in\\mathbb{R}$, for $n\\ge 0$\n",
    ">\n",
    "> $$ x_{n+1} = g(x_n). $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary\n",
    "\n",
    "- If repeated applications of a function $g$ converges to $\\xi$, then it solves $x=g(x)$. (Some condition on $f$ is needed: see Analysis below.)\n",
    "- If converges, the fixed point iteration method converges *linearly*: there exists $C>0$ such that $e_{k+1}\\approx \\lambda e_k$ with $0<\\lambda<1$. \n",
    "- If you want to solve the equation $f(x)=0$, set $g(x):=x+f(x)$ and apply the fixed point iteration to $g$. Then, the fixed point $\\xi$ satisfies \n",
    "    $$\\xi = g(\\xi)=\\xi+f(\\xi) \\quad \\text{implies} \\quad f(\\xi)=0.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis\n",
    "\n",
    "![Fixed point, contraction, and contraction mapping theorem](https://jhparkyb.github.io/resources/notes/na/104ASlides_RootFinding024.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![proof of contraction mapping theorem](https://jhparkyb.github.io/resources/notes/na/104ABoardWork_RootFinding015.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparisons of root-finding methods\n",
    "\n",
    "| | Bisection | Newton | Secant | Fixed point |\n",
    "|:--:|:--:|:--:|:--:|:--:|\n",
    "| need $f(x)$ | O | O | O | O |\n",
    "| need $f'(x)$ | - | O | - | - |\n",
    "| rate of convergence | 1 | 2 | 1.618 | 1 |\n",
    "| rate of convergence <br> per two function eval's | 2 | 2 | 3.236 | 2 |\n",
    "| global convergence | yes <br> if $f(a)f(b)<0$ | no | no | yes <br> if contractive |\n",
    "| solution boxed | yes | no | no | generally, no |  \n",
    "| generalization <br> to high dimensions <br> (intellectual effort) | awkward | yes, <br> but gradient may not be available | yes, <br> but not very trival <br> (called quasi-Newton methods)| yes |\n",
    "| generalization <br> to high dimensions <br> (numerical aspects) | N/A | demanding | depends | depends |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---\n",
    "This work is licensed under [Creative Commons Attribution-ShareAlike 4.0 International](https://creativecommons.org/licenses/by-sa/4.0/)\n",
    "Part of the content of this notebook is borrowed from [Elementary Numerical Analysis (with Python)](https://lemesurierb.people.cofc.edu/elementary-numerical-analysis-python/preface.html) written by Brenton LeMesurier, College of Charleston and University of Northern Colorado. Thanks to Dr. LeMesurier for sharing excellent notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
